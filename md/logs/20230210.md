# 實習日誌 20230210

## 09:00 收尾

撰寫實習紀錄的任務成果、昨天的實習日誌。

## 11:00 大致完成

只剩下小編天堂路的截圖待確認可否公開。

產出文件並上傳到 GitHub。

## 11:30 人物去背

傳訊息給導師：＂你好，我之前的任務都整理好了，也有在工程師實習生任務清單做紀錄，請問有沒有新的任務＂。導師傳來一個雙手比讚的貼圖，還有新的任務：

> 我們之後要做一個 WEB-AR 會套上 facemesh 這個 facemesh 的圖設計會做  
> 可不可以幫我研究 這個 mindar+threeJS 是否可以加上人物去背功能  
> [ThreeJS FaceMesh](https://hiukim.github.io/mind-ar-js-doc/more-examples/threejs-face-facemesh)  
> 感謝

我回覆收到。

導師補充說明：

> 可能關鍵字是 Segmentation  
> 或是否有其他免費套件 也可實現 facemesh + Segmentation  
> [Spark AR 人物外框效果 | Background Remove with Outline Effect](https://medium.com/@pofu.lu/spark-ar-%E4%BA%BA%E7%89%A9%E5%A4%96%E6%A1%86%E6%95%88%E6%9E%9C-background-remove-with-outline-effect-f6449563ea66)

## 12:00 午餐

---

## 13:00 回到家裡

用 MindAR, Threejs, AR, 人物去背, Face Mesh, Segmentation 等關鍵字搜尋，找到 Meta Spark Studio 的說明文章。

傳訊息給導師：

> 目前查到的資料  
> Meta Spark Studio 可以做到 face mesh 和 people segmentation  
> [Introduction to People Effects](https://sparkar.facebook.com/ar-studio/learn/articles/people-tracking/people-effects-introduction)

## 14:00 排除選項

導師的回覆是＂除了spark ar 之外 是否有網頁可做到呢，因為 spark ar 只能套在 fb/ig app 上不能放在網頁上，因為我知道 spark ar 可作＂。

換了好幾個關鍵字組合，用進階搜尋排除有 Spark 的搜尋結果，最後用 WEB AR people segmentation -Spark 這串關鍵字，找到 TensorFlow 的文章，[Body Segmentation with MediaPipe and TensorFlow.js](https://blog.tensorflow.org/2022/01/body-segmentation.html)，。

於是去看 [TensorFlow 模型列表](https://www.tensorflow.org/js/models)。裡面有 [Face Landmarks Detection](https://github.com/tensorflow/tfjs-models/tree/master/face-landmarks-detection) 和 [Body Segmentation](https://github.com/tensorflow/tfjs-models/tree/master/body-segmentation)。

在 TensorFlow.js 的上述兩個模型的說明文件都有提到它們提供的模型選項有 MediaPipe。

於是去看 [MediaPipe 官方網站](https://mediapipe.dev/)，裡面有 [MediaPipe Face Mesh](https://google.github.io/mediapipe/solutions/face_mesh.html) 和 [MediaPipe Selfie Segmentation](https://google.github.io/mediapipe/solutions/selfie_segmentation.html)。應該是目前的最佳解。

## 16:00 系統限制

傳訊息給導師：＂找到 [MediaPipe](https://mediapipe.dev/)，同時有 Selfie Segmentation 和 Face Mesh＂。導師回覆＂感覺不錯 能試試看幫我用 javascript 寫個facemesh + 去背的 demo 嗎＂。

我打開 MediaPipe 官方的 Codepen demo，已經開啟攝影機了還是無法使用，回去查文件才看到 [Can I run MediaPipe on MS Windows?](https://google.github.io/mediapipe/getting_started/faq.html#can-i-run-mediapipe-on-ms-windows)，Currently MediaPipe portability supports Debian Linux, Ubuntu Linux, MacOS, Android, and iOS，唯獨不支援 Windows。可是 [MediaPipe in JavaScript Supported platforms](https://google.github.io/mediapipe/getting_started/javascript#supported-plaforms) 又說有支援 Windows？？？

用自己的手機開啟此範例就成功了。

## 16:30 確認需求

我傳訊息問導師＂請問這個 AR 需要支援哪些裝置＂，導師回答＂手機瀏覽器 safari chrome＂。

新增一個 Codepen 檔案，嘗試合併 MediaPipe 的 Face Mesh 和 Selfie Segmentation 的 demo 程式碼。

## 17:30 回報進度

我傳訊息給導師＂目前在嘗試合併 MediaPipe 的 Face Mesh 和 Selfie Segmentation 的 demo 程式碼，不過還沒成功＂，導師回覆＂了解，辛苦了，下禮拜四再繼續好了＂。

我回覆＂收到，另外想請問小編天堂路可以截圖嗎？＂，導師說可以。我回覆感謝，並再提出一個問題＂最後想請問生命靈數測驗實際上線了嗎＂，導師說＂還沒，他們在換窗口，有消息會跟你說＂，我回覆＂了解，那我先下班了，下周再繼續＂。

## 18:30 下班

## 本日心得

在 Codepen 合併兩個範例，有些東西要共用，有些要分開，各種變數與常數名稱直接撞名撞到死。我還是用本機檔案處理好了。

> :ToCPrevNext